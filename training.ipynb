{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Girish\\.conda\\envs\\venv\\Lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Girish\\.conda\\envs\\venv\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from training_enhanced import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='xpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Device Setup ---\n",
    "device = torch.device(\"xpu\" if torch.xpu.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Paths, Tokenizer, Dataset, and DataLoader ---\n",
    "IMAGE_DIR = \"train2017_50k\"\n",
    "FEATURES_DIR = \"train2017_50k_features_en\"\n",
    "CAPTIONS_FILE = \"merged_captions.json\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer.bos_token = \"[CLS]\"\n",
    "tokenizer.eos_token = \"[SEP]\"\n",
    "tokenizer.bos_token_id = tokenizer.convert_tokens_to_ids(\"[CLS]\")\n",
    "tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(\"[SEP]\")\n",
    "\n",
    "max_length = 50\n",
    "dataset = ImageCaptionDataset(IMAGE_DIR, CAPTIONS_FILE, tokenizer, max_length=max_length, use_features=True, features_dir=FEATURES_DIR)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing features: 100%|██████████| 500/500 [54:52<00:00,  6.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# --- Precompute Features ---\n",
    "# encoder = EfficientNetEncoder()\n",
    "# precompute_features(dataset, encoder, device, FEATURES_DIR, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Train, Validation, and Test Splits ---\n",
    "batch_size = 32\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, persistent_workers=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, persistent_workers=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, persistent_workers=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "embed_dim = 512\n",
    "num_heads = 8\n",
    "hidden_dim = 2048\n",
    "num_layers = 6\n",
    "dropout = 0.2\n",
    "feature_dim = 1792\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "# --- High Compute Hyperparameters --- \n",
    "# embed_dim = 256\n",
    "# hidden_dim = 1024\n",
    "# num_heads = 16  # More attention heads\n",
    "# num_layers = 6  # Deeper model\n",
    "# dropout = 0.2\n",
    "# feature_dim = 960\n",
    "\n",
    "# --- Instantiate Encoder, Decoder, and Model ---\n",
    "encoder = EfficientNetEncoder()\n",
    "decoder = TransformerDecoder(\n",
    "    embed_dim=embed_dim,        \n",
    "    num_heads=num_heads,      \n",
    "    hidden_dim=hidden_dim,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    num_layers=num_layers,    \n",
    "    max_length=max_length,\n",
    "    feature_dim=feature_dim,\n",
    "    dropout=dropout\n",
    ")\n",
    "model = ImageCaptionModel(encoder, decoder, use_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Girish\\.conda\\envs\\venv\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The argument `model_name_or_path` was not specified while it is required when the default `transformers` model is used. It will use the default recommended model - 'roberta-large'.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- Loss, Optimizer, Scheduler and Training ---\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=2)\n",
    "num_epochs = 50\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "model, optimizer = ipex.optimize(model, optimizer=optimizer)\n",
    "# model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "trainer = ImageCaptionTrainer(model, tokenizer, criterion, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1250/1250 [07:14<00:00,  2.88it/s, loss=3.2695]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 4.0235 | Val Loss: 3.1067 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 3.1067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1250/1250 [06:59<00:00,  2.98it/s, loss=2.5017]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 2.9507 | Val Loss: 2.7084 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1250/1250 [07:00<00:00,  2.98it/s, loss=2.7224]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 2.6355 | Val Loss: 2.5426 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.5426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1250/1250 [07:11<00:00,  2.90it/s, loss=2.2854]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 2.4458 | Val Loss: 2.4249 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.4249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1250/1250 [07:31<00:00,  2.77it/s, loss=2.3916]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 2.3048 | Val Loss: 2.3583 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.3583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1250/1250 [07:21<00:00,  2.83it/s, loss=2.2293]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 2.1909 | Val Loss: 2.3218 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.3218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1250/1250 [07:19<00:00,  2.84it/s, loss=2.1898]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 2.0922 | Val Loss: 2.2813 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.2813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1250/1250 [07:22<00:00,  2.83it/s, loss=2.0460]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 2.0031 | Val Loss: 2.2744 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.2744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1250/1250 [07:21<00:00,  2.83it/s, loss=1.9321]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.9209 | Val Loss: 2.2646 | LR: 0.000100\n",
      "--> Best model saved. | Val loss 2.2646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1250/1250 [07:38<00:00,  2.73it/s, loss=1.9549]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.8435 | Val Loss: 2.2650 | LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 1250/1250 [07:10<00:00,  2.90it/s, loss=1.7347]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.7681 | Val Loss: 2.2683 | LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 1250/1250 [06:52<00:00,  3.03it/s, loss=1.8081]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.6953 | Val Loss: 2.2792 | LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 1250/1250 [06:50<00:00,  3.04it/s, loss=1.5428]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.5330 | Val Loss: 2.2667 | LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 1250/1250 [06:50<00:00,  3.04it/s, loss=1.5429]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.4871 | Val Loss: 2.2836 | LR: 0.000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 1250/1250 [06:51<00:00,  3.04it/s, loss=1.4619]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.4534 | Val Loss: 2.2979 | LR: 0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 1250/1250 [06:52<00:00,  3.03it/s, loss=1.3804]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 1.3948 | Val Loss: 2.2950 | LR: 0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 1250/1250 [06:53<00:00,  3.02it/s, loss=1.3325]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 1.3805 | Val Loss: 2.2967 | LR: 0.000009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 1250/1250 [06:53<00:00,  3.03it/s, loss=1.4249]\n",
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 1.3695 | Val Loss: 2.3042 | LR: 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 1250/1250 [06:51<00:00,  3.04it/s, loss=1.2540]\n",
      "                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 1.3493 | Val Loss: 2.3040 | LR: 0.000003\n",
      "Early stopping triggered!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, val_loader, num_epochs, patience=10, min_delta=0.001, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"last_model.pth\")\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "trainer.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 157/157 [2:02:12<00:00, 46.71s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BLEU Score... 0.0740467658803539\n",
      "Computing CIDEr... 0.30955993101206697\n",
      "Computing METEOR... 0.2613576305799852\n",
      "Computing ROUGE-L Score... 0.2964625358581543\n",
      "Computing BERT Score... 0.9674673080444336\n",
      "BLEU Score: 0.0740\n",
      "CIDEr Score: 0.3096\n",
      "METEOR Score: 0.2614\n",
      "ROUGE-L Score: 0.2965\n",
      "BERT Score: 0.9675\n"
     ]
    }
   ],
   "source": [
    "# --- After Training, Evaluate on the Test Set (Greedy Decoding) ---\n",
    "metrics = trainer.evaluate_test_set(test_loader, max_length)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
