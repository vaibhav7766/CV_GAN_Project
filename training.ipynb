{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Device Setup ---\n",
    "device = torch.device(\"xpu\" if torch.xpu.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Paths, Tokenizer, Dataset, and DataLoader ---\n",
    "IMAGE_DIR = \"train2017_50k\"\n",
    "FEATURES_DIR = \"train2017_50k_features\"\n",
    "CAPTIONS_FILE = \"merged_captions.json\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nemotron_tokenizer\")\n",
    "max_length = 50\n",
    "dataset = ImageCaptionDataset(IMAGE_DIR, CAPTIONS_FILE, tokenizer, max_length=max_length, use_features=True, features_dir=FEATURES_DIR)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Precompute Features ---\n",
    "# encoder = MobileNetV3Encoder()\n",
    "# precompute_features(dataset, encoder, device, FEATURES_DIR, batch_size=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create Train, Validation, and Test Splits ---\n",
    "batch_size = 8\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hyperparameters ---\n",
    "embed_dim = 512\n",
    "num_heads = 8\n",
    "hidden_dim = 512\n",
    "num_layers = 6\n",
    "dropout = 0.2\n",
    "feature_dim = 960\n",
    "\n",
    "# --- Instantiate Encoder, Decoder, and Model ---\n",
    "encoder = MobileNetV3Encoder()\n",
    "decoder = TransformerDecoder(\n",
    "    embed_dim=embed_dim,        \n",
    "    num_heads=num_heads,      \n",
    "    hidden_dim=hidden_dim,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    num_layers=num_layers,    \n",
    "    max_length=max_length,\n",
    "    feature_dim=feature_dim,\n",
    "    dropout=dropout\n",
    ")\n",
    "model = ImageCaptionModel(encoder, decoder, use_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss, Optimizer, Scheduler and Training ---\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)  \n",
    "\n",
    "num_epochs = 50\n",
    "scheduler = ReduceLROnPlateau(optimizer)\n",
    "\n",
    "model.train()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "model, optimizer = ipex.optimize(model, optimizer=optimizer)\n",
    "# model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "trainer = ImageCaptionTrainer(model, tokenizer, criterion, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_loader, val_loader, num_epochs, patience=10, min_delta=0.001, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"last_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- After Training, Evaluate on the Test Set ---\n",
    "metrics = trainer.evaluate_test_set(test_loader, max_length)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load best model then check bleu score ---\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", weights_only=True))\n",
    "trainer.model = model\n",
    "metrics = trainer.evaluate_test_set(test_loader, max_length)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
